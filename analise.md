# Desafio Kaggle Open Challenge - Vivi

## ğŸ’¥ CompreensÃ£o do desafio
O objetivo central deste desafio Ã© desenvolver um modelo preditivo robusto capaz de estimar com precisÃ£o os preÃ§os finais das casas residenciais em Ames, Iowa. Para isso, o desafio se baseia em prÃ¡ticas avanÃ§adas de modelagem, incluindo o uso de modelos de regressÃ£o linear (Ridge e Lasso) e tÃ©cnicas de regularizaÃ§Ã£o. 

## Conjunto de Dados
O conjunto de dados abrange 79 variÃ¡veis explicativas, oferecendo uma visÃ£o das caracterÃ­sticas fÃ­sicas, condiÃ§Ãµes e atributos das residÃªncias. A competiÃ§Ã£o desafia os participantes a explorar e modelar essas variÃ¡veis para extrair padrÃµes que influenciam significativamente os preÃ§os imobiliÃ¡rios.

### ğŸ—ƒ Arquivos 
O processo Ã© dividido em trÃªs arquivos principais: pipeline.py, preprocessors.py e trainer.py. Cada arquivo desempenha um papel especÃ­fico na construÃ§Ã£o e avaliaÃ§Ã£o do modelo.

#### ğŸ—‚ Arquivo pipeline.py

Possui 3 funÃ§Ãµes:
* **'create_preproc()'**: cria um pipeline de prÃ©-processamento para os dados dividido em trÃªs partes: numÃ©rico, ordinal e nominal.
* **'create_model()'**:  cria um modelo empilhado (StackingRegressor) composto por diferentes regressores: Gradient Boosting, AdaBoost, Ridge e SVM. O regressor final Ã© uma RegressÃ£o Linear.
* **'create_pipeline()'**: combina o prÃ©-processamento e o modelo em um Ãºnico pipeline usando a funÃ§Ã£o make_pipeline do scikit-learn.

#### ğŸ—‚ Arquivo preprocessors.py

Possui 3 funÃ§Ãµes:
* **'create_preproc_ordinal()'**: cria um prÃ©-processador especÃ­fico para caracterÃ­sticas ordinais.
  - ImputaÃ§Ã£o de valores ausentes com a categoria "missing".
  - CodificaÃ§Ã£o ordinal usando OrdinalEncoder.
  - NormalizaÃ§Ã£o das caracterÃ­sticas usando MinMaxScaler.

* **'create_preproc_numerical()'**: cria um prÃ©-processador especÃ­fico para caracterÃ­sticas numÃ©ricas.
  - ImputaÃ§Ã£o de valores ausentes usando KNNImputer.
  - NormalizaÃ§Ã£o das caracterÃ­sticas usando MinMaxScaler.

* **'create_preproc_nominal()'**: cria um prÃ©-processador especÃ­fico para caracterÃ­sticas nominais.
  - ImputaÃ§Ã£o de valores ausentes usando a estratÃ©gia "most_frequent" (SimpleImputer).
  - CodificaÃ§Ã£o one-hot usando OneHotEncoder.

#### ğŸ—‚ Arquivo trainer.py

A classe Trainer Ã© responsÃ¡vel por carregar os dados, construir o pipeline e realizar a validaÃ§Ã£o cruzada. Isso Ã© feito a partir da criaÃ§Ã£o de uma instÃ¢ncia do Trainer feita pelo script.

**MÃ©todos:**

  â†’ load_data(): Carrega os dados do conjunto de treinamento.

  â†’ build_pipeline(feature_cutoff_percentage=75): ConstrÃ³i o pipeline chamando as funÃ§Ãµes em "pipeline.py".

  â†’ cross_validate(cv=5): Realiza a validaÃ§Ã£o cruzada e imprime o RMSLE mÃ©dio e desvio padrÃ£o.


AlÃ©m desses 3 arquivos principais, o desafio possui outros 3 sendo de teste. Eles fornecem casos de teste automatizados para verificar se os diferentes componentes estÃ£o funcionando conforme esperado.

#### ğŸ—‚ Arquivo test_features_overview.py

  ContÃ©m um caso de teste para verificar se o nÃºmero de caracterÃ­sticas categÃ³ricas estÃ¡ correto.

#### ğŸ—‚ Arquivo test_preproc_baseline.py

  ContÃ©m um caso de teste para verificar se a forma do conjunto de dados apÃ³s o prÃ©-processamento estÃ¡ correta.

#### ğŸ—‚ Arquivo test_submission_baseline.py

  ContÃ©m vÃ¡rios casos de teste relacionados Ã  submissÃ£o de resultados.

#### ğŸ—‚ **DescriÃ§Ãµes de outros arquivos**

  - **train.csv**: conjunto de treinamento
    
  - **test.csv**: conjunto de testes
    
  - **data_description.txt**: descriÃ§Ã£o completa de cada coluna, originalmente preparada por Dean De Cock, mas ligeiramente editada para corresponder aos nomes das colunas usados aqui
    
  - **sample_submission.csv**: envio de referÃªncia de uma regressÃ£o linear no ano e mÃªs da venda, metragem quadrada do lote e nÃºmero de quartos


## MÃ©todos de treinamento - Modelo Essemble

### ğŸ©· Modelo Ridge Regression


### â¤ï¸ Modelo KNN

### ğŸ§¡ Modelo Decision Tree

### ğŸ’› Modelo SVM (Support Vector Machine)

### ğŸ’š Modelo RandomForest

### ğŸ©µ Modelo AdaBoost

### ğŸ’™ Modelo GradientBoosting

### ğŸ’œ Modelo Stacking


## PossÃ­veis melhorias:
- **ExperimentaÃ§Ã£o com CodificaÃ§Ã£o CategÃ³rica:** explorar diferentes formas de codificaÃ§Ã£o para caracterÃ­sticas categÃ³ricas, incluindo outras tÃ©cnicas alÃ©m da codificaÃ§Ã£o ordinal e one-hot.
- **Refinamento na SeleÃ§Ã£o de CaracterÃ­sticas:** reduzir o nÃºmero de caracterÃ­sticas para evitar overfitting, melhorar a eficiÃªncia do modelo e identificar as caracterÃ­sticas mais impactantes para a previsÃ£o de preÃ§os.
- **TransformaÃ§Ã£o LogarÃ­tmica do Alvo:** avaliar a transformaÃ§Ã£o logarÃ­tmica do alvo (y_log) para obter uma distribuiÃ§Ã£o mais normal.
- **OtimizaÃ§Ã£o Adicional dos HiperparÃ¢metros:** realizar uma otimizaÃ§Ã£o mais detalhada dos hiperparÃ¢metros para levar a um desempenho ainda mais aprimorado do modelo.
